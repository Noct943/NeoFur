# Neofur智能兽装
**旨在打造全功能、可交互、仿生的智能穿戴机器人系统**
    
Neofur是以兽装（布偶装）为模板，打造一个集成了多路视觉、眼动追踪、动态表情、机械运动和语音交互的综合平台。本项目以 ROS 2 为核心，将所有硬件子系统解耦为独立的模块化节点，实现复杂功能的协同工作。

## 系统架构总览
以嵌入式主控 RK3588s 为核心，运行 Ubuntu 20.04 和 ROS 2 Foxy，协调五大核心子系统。
<img width="1908" height="1796" alt="思维导图1 0" src="https://github.com/user-attachments/assets/64235603-3374-44d0-b435-62662cbd07e2" />

### 👁️ 电子眼系统
负责所有的动态表情展示

**显示:** 通过 **DRM** 接口直接驱动两块 720*720 的圆形MIPI屏幕，实现实时渲染。

**渲染:** 内部采用四层渲染架构（平台/渲染/场景/应用），基于**OpenGL ES**和**Magnum**引擎，支持加载 **glTF PBR**模型。
* 平台抽象层(PAL)：封装底层硬件接口，通过DRM/KMS实现最高性能的直接屏幕渲染。
* 渲染抽象层(RAL)：基于Magnum引擎封装OpenGL ES，为上层提供现代、安全的图形API接口。
* 场景与图形层(SGL)：加载并管理glTF场景，定义由PBR材质和网格构成的视觉世界。
* 应用层(AL)：作为ROS 2节点担当总指挥，接收指令，更新场景并驱动渲染循环。

**感知:**
OV9281 虹膜夜视摄像头用于眼动追踪，捕捉穿戴者的视线。
BH1750 光强传感器用于亮度检测，使眼睛亮度能自适应环境。

### 🎥 图传系统
为穿戴者提供清晰的外部视野

**视觉:** 通过两颗摄像头实现双目视觉采集。
**显示:**将采集到的画面实时传输到头盔内部的两块屏幕上，通过 HDMI 连接。

### 🦾 运动控制系统
赋予兽装物理上的“生命感”

**驱动：**通过伺服电机-丝杆驱动可动耳朵和可动颚，实现丰富的表情和动作。

**姿态感知:** 集成陀螺仪(IMU)，捕捉头部姿态，实现耳朵和下颚的联动。

### 🎤 内外沟通系统 
实现与外界的无缝交流。

**输入:** 通过麦克风阵列进行声源定位和语音识别，接收语音指令。

**输出: **通过扩音器向外播放声音。

**交互:** 支持远程语音功能，并可通过蓝牙/WiFi进行数据交互。

### ✨ 视觉特效系统

**灯光:** 通过 3.5mm 音频接口驱动发光花纹，实现与声音或状态联动的酷炫灯效。


## 📅更新记录：
* 0.0.1
    
  完成对libDRM库的C++封装，实现mipi驱动720*720 4寸圆屏显示眼睛图像和坐标移动。
* 0.0.2
  
  引入RGA优化图像帧显示、合成、移动。

* 0.0.3

  完成渲染管线设计，基于OpenGL ES和Magnum引擎，实现加载glTF模型（**因暂无可用模型，未经测试**）
  
